{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simone tries to be usefull and fail part 546\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event from 2018-04-20 21:00:00 to 2018-04-21 09:00:00\n",
      "Running IRI for 2018-04-20 with F10.7=73.0 hours=[21.   21.25 21.5  21.75 22.   22.25 22.5  22.75 23.  ]\n",
      "Running IRI for 2018-04-21 with F10.7=76.8 hours=[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.   2.25 2.5  2.75 3.   3.25\n",
      " 3.5  3.75 4.   4.25 4.5  4.75 5.   5.25 5.5  5.75 6.   6.25 6.5  6.75\n",
      " 7.   7.25 7.5  7.75 8.   8.25 8.5  8.75 9.  ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyIRI\n",
    "import PyIRI.edp_update as ml\n",
    "import PyIRI.plotting as plot\n",
    "\n",
    "# --- Define event start and end ---\n",
    "start_date_string = '2018-04-20 21:00:00'\n",
    "#end_date_string = '2018-04-21 03:00:00'\n",
    "#'2024-06-29T18:00:00'  # Example: spans to next day\n",
    "\n",
    "start_date = pd.to_datetime(start_date_string)\n",
    "\n",
    "#make the end the start dat + 12 hours\n",
    "end_date_string = (start_date + pd.Timedelta(hours=12)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "end_date = pd.to_datetime(end_date_string)\n",
    "\n",
    "print(f\"Event from {start_date} to {end_date}\")\n",
    "\n",
    "# --- Load F10.7 index ---\n",
    "indices_F10 = pd.read_csv('/mnt/ionosphere-data/solar_env_tech_indices/Indices_F10_processed.csv')\n",
    "indices_F10['Datetime'] = pd.to_datetime(indices_F10['Datetime'])\n",
    "\n",
    "# Filter for the event date range (normalized to days)\n",
    "dates_in_event = pd.date_range(start=start_date.normalize(), end=end_date.normalize(), freq='D')\n",
    "\n",
    "# Build list of day-wise tuples for IRI input\n",
    "iri_runs = []\n",
    "for date in dates_in_event:\n",
    "    day_start = max(start_date, date)\n",
    "    day_end = min(end_date, date + pd.Timedelta(days=1) - pd.Timedelta(seconds=1))\n",
    "\n",
    "    hr_res = 0.25 # 15 minute cadence generation\n",
    "\n",
    "    # Create hourly range within the current day\n",
    "    ahr = np.arange(day_start.hour, day_end.hour + hr_res, hr_res)\n",
    "\n",
    "    # Get F10.7 value for this date (or fallback)\n",
    "    f10_row = indices_F10[indices_F10['Datetime'] == date]\n",
    "    f107 = f10_row['F10'].values[0] if not f10_row.empty else 150.0\n",
    "\n",
    "    iri_runs.append({\n",
    "        \"year\": date.year,\n",
    "        \"month\": date.month,\n",
    "        \"day\": date.day,\n",
    "        \"ahr\": ahr,\n",
    "        \"f107\": f107\n",
    "    })\n",
    "\n",
    "# --- Spatial and altitude grids ---\n",
    "dlon = 1\n",
    "dlat = 1\n",
    "alon_2d, alat_2d = np.mgrid[-180:180:dlon, -90:90:dlat]\n",
    "alon = np.reshape(alon_2d, alon_2d.size)\n",
    "alat = np.reshape(alat_2d, alat_2d.size)\n",
    "\n",
    "alt_res = 720\n",
    "alt_min = 0\n",
    "alt_max = 36000\n",
    "aalt = np.arange(alt_min, alt_max, alt_res)\n",
    "\n",
    "ccir_or_ursi = 1  # IRI option\n",
    "\n",
    "# --- Run pyIRI for each day/hour range ---\n",
    "all_edp = []\n",
    "for run in iri_runs:\n",
    "    print(f\"Running IRI for {run['year']}-{run['month']:02}-{run['day']:02} with F10.7={run['f107']} hours={run['ahr']}\")\n",
    "\n",
    "    f2, f1, e_peak, es_peak, sun, mag, edp = ml.IRI_density_1day(\n",
    "        run[\"year\"], run[\"month\"], run[\"day\"],\n",
    "        run[\"ahr\"], alon, alat, aalt,\n",
    "        run[\"f107\"], PyIRI.coeff_dir, ccir_or_ursi\n",
    "    )\n",
    "    all_edp.append(edp)\n",
    "\n",
    "\n",
    "# You can now concatenate or analyze the EDP results in `all_edp`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEC computed for day 1, shape: (9, 64800)\n",
      "TEC computed for day 2, shape: (37, 64800)\n"
     ]
    }
   ],
   "source": [
    "# --- Compute TEC for each EDP in all_edp ---\n",
    "all_tec = []\n",
    "for i, edp in enumerate(all_edp):\n",
    "    tec = PyIRI.main_library.edp_to_vtec(edp, aalt, min_alt=0.0, max_alt=36000.)\n",
    "    all_tec.append(tec)\n",
    "    print(f\"TEC computed for day {i + 1}, shape: {tec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tec_for_datetime(target_dt, iri_runs, all_tec, alon_2d):\n",
    "    for i, run in enumerate(iri_runs):\n",
    "        date = pd.Timestamp(run[\"year\"], run[\"month\"], run[\"day\"])\n",
    "        ahr = run[\"ahr\"]\n",
    "        start_hr = date + pd.to_timedelta(ahr[0], unit=\"h\")\n",
    "        end_hr = date + pd.to_timedelta(ahr[-1], unit=\"h\")\n",
    "\n",
    "        if start_hr <= target_dt <= end_hr:\n",
    "            # Convert target time to fractional hour\n",
    "            target_hr = (target_dt - date).total_seconds() / 3600.0\n",
    "            hour_idx = np.argmin(np.abs(ahr - target_hr))\n",
    "\n",
    "            tec_flat = all_tec[i][hour_idx]\n",
    "            tec_2d = tec_flat.reshape(alon_2d.shape)\n",
    "            return np.rot90(tec_2d), target_hr\n",
    "\n",
    "    raise ValueError(\"Target datetime not in any IRI time range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "target_dt = start_date#pd.Timestamp(\"2024-06-29T00:00:00\")\n",
    "tec_2d, matched_hr = get_tec_for_datetime(target_dt, iri_runs, all_tec, alon_2d)\n",
    "\n",
    "print(f\"TEC for {target_dt} (closest match: {matched_hr:.2f} UTC)\")\n",
    "\n",
    "# Now plot `tec_2d` as usual\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = fig.add_subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "im = ax.imshow(\n",
    "    tec_2d,\n",
    "    extent=[-180, 180, -90, 90],\n",
    "    origin='upper',  # Use 'lower' so that latitudes are plotted correctly\n",
    "    cmap='jet',\n",
    "    vmin=0,\n",
    "    vmax=np.percentile(tec_2d, 95),\n",
    "    transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Add geographic features\n",
    "ax.coastlines(color='white', linewidth=0.5)\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.3)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.6, pad=0.02)\n",
    "cbar.set_label('VTEC (TECU)', fontsize=12)\n",
    "\n",
    "plt.title(\"Vertical TEC\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import io\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def convert_to_doy(date_obj):\n",
    "    \"\"\"Convert datetime object to zero-padded day of year string (e.g., '001', '059').\"\"\"\n",
    "    doy = date_obj.timetuple().tm_yday\n",
    "    return f\"{doy:03d}\"\n",
    "\n",
    "def list_jpld_files(data_dir, start_date, end_date):\n",
    "    \"\"\"\n",
    "    List JPLD files in folder matching the date range.\n",
    "    Filenames like: 'jpld{DOY}0.{YYYY}i.nc.gz'\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "    date_range = pd.date_range(start=start_date.normalize(), end=end_date.normalize(), freq='D')\n",
    "    year_str = str(start_date.year)[2:]\n",
    "    \n",
    "    for date in date_range:\n",
    "        doy_str = convert_to_doy(date)\n",
    "        print(f\"Checking for file: jpld{doy_str}0.{year_str}i.nc.gz\")\n",
    "        filename = f\"jpld{doy_str}0.{year_str}i.nc.gz\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            file_list.append(filepath)\n",
    "        else:\n",
    "            print(f\"Warning: File not found {filepath}\")\n",
    "    return file_list\n",
    "\n",
    "def load_jpld_data(files, target_start_dt, target_end_dt):\n",
    "    \"\"\"\n",
    "    Load and extract TEC maps for times within [target_start_dt, target_end_dt].\n",
    "    Returns:\n",
    "        - List of TEC arrays with shape (time, lat, lon)\n",
    "        - latitudes, longitudes arrays\n",
    "        - list of datetime objects matching each time slice\n",
    "    \"\"\"\n",
    "    all_tec = []\n",
    "    all_times = []\n",
    "    lat, lon = None, None\n",
    "    \n",
    "    j2000 = datetime(2000, 1, 1, 12, 0, 0)\n",
    "    \n",
    "    for fpath in files:\n",
    "        with gzip.open(fpath, 'rb') as f:\n",
    "            decompressed_data = f.read()\n",
    "        nc_buffer = io.BytesIO(decompressed_data)\n",
    "        with Dataset('in_memory.nc', mode='r', memory=nc_buffer.read()) as nc:\n",
    "            time_seconds = nc.variables['time'][:]\n",
    "            times = [j2000 + timedelta(seconds=float(t)) for t in time_seconds]\n",
    "            \n",
    "            # Select indices within target time interval\n",
    "            indices = [i for i, t in enumerate(times) if target_start_dt <= t <= target_end_dt]\n",
    "            \n",
    "            if len(indices) == 0:\n",
    "                continue  # no relevant data in this file\n",
    "            \n",
    "            tecmap = nc.variables['tecmap'][:]  # shape (time, lat, lon)\n",
    "            if lat is None or lon is None:\n",
    "                lat = nc.variables['lat'][:]\n",
    "                lon = nc.variables['lon'][:]\n",
    "            \n",
    "            # Extract only the relevant time slices\n",
    "            tec_subset = tecmap[indices, :, :]\n",
    "            all_tec.append(tec_subset)\n",
    "            all_times.extend([times[i] for i in indices])\n",
    "    \n",
    "    if len(all_tec) == 0:\n",
    "        raise RuntimeError(\"No TEC data found for given date/time range.\")\n",
    "    \n",
    "    # Concatenate all days along the time dimension\n",
    "    all_tec = np.concatenate(all_tec, axis=0)\n",
    "    \n",
    "    return all_tec, lat, lon, all_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your event start and end times (matching your IRI inputs)\n",
    "# start_date = pd.to_datetime('2024-06-28T09:00:00')\n",
    "# end_date = pd.to_datetime('2024-06-29T18:00:00')\n",
    "\n",
    "# Folder where JPLD files are stored (update accordingly)\n",
    "jpld_dir_path = f'/mnt/ionosphere-data/jpld/raw/{start_date.year}/'\n",
    "\n",
    "# Step 1: List relevant files\n",
    "jpld_files = list_jpld_files(jpld_dir_path, start_date, end_date)\n",
    "\n",
    "# Step 2: Load data and extract time slices matching event time range\n",
    "tec_data, lat, lon, tec_times = load_jpld_data(jpld_files, start_date, end_date)\n",
    "\n",
    "print(f\"Loaded TEC data shape: {tec_data.shape}\")\n",
    "print(f\"Number of time steps: {len(tec_times)}\")\n",
    "\n",
    "# Now you have:\n",
    "# tec_data: array of shape (time, lat, lon), 15-minute cadence (usually 96 per day)\n",
    "# lat, lon: coordinate arrays\n",
    "# tec_times: datetime list for each time index\n",
    "\n",
    "# Optional: flip latitudes if needed for consistency with IRI data\n",
    "tec_data = np.flip(tec_data, axis=1)  # flips lat axis\n",
    "\n",
    "# Step 3: Create a structure similar to IRI outputs\n",
    "jpld_struct = {\n",
    "    \"tec\": tec_data,\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon,\n",
    "    \"times\": tec_times\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "\n",
    "def plot_tec_map(time_idx, data_struct):\n",
    "    tec_map = data_struct[\"tec\"][time_idx, :, :]\n",
    "    lat = data_struct[\"lat\"]\n",
    "    lon = data_struct[\"lon\"]\n",
    "    dt = data_struct[\"times\"][time_idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    im = ax.pcolormesh(lon, lat, np.log10(tec_map), cmap='jet', vmin=0, vmax=1.5, shading='auto')\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3)\n",
    "    ax.set_title(f'JPLD GNSS GIM TEC Map on {dt.strftime(\"%Y-%m-%d %H:%M UTC\")}', fontsize=14)\n",
    "    plt.colorbar(im, ax=ax, label='log10(TEC)')\n",
    "    plt.show()\n",
    "\n",
    "# Plot first time slice\n",
    "plot_tec_map(0, jpld_struct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "iri_times = []\n",
    "for run in iri_runs:\n",
    "    base_date = datetime(run[\"year\"], run[\"month\"], run[\"day\"])\n",
    "    for hour in run[\"ahr\"]:\n",
    "        iri_times.append(base_date + timedelta(hours=float(hour)))\n",
    "\n",
    "\n",
    "matched_indices = []\n",
    "for iri_time in iri_times:\n",
    "    time_diffs = np.array([abs((jpld_t - iri_time).total_seconds()) for jpld_t in jpld_struct['times']])\n",
    "    closest_idx = time_diffs.argmin()\n",
    "    matched_indices.append(closest_idx)\n",
    "\n",
    "\n",
    "def plot_side_by_side(iri_tec, jpld_tec, lat, lon, dt):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    # Plot IRI TEC\n",
    "    ax = axs[0]\n",
    "    im = ax.imshow(\n",
    "        iri_tec, extent=[-180, 180, -90, 90], origin='upper', cmap='jet',\n",
    "        vmin=0, vmax=np.percentile(iri_tec, 95), transform=ccrs.PlateCarree()\n",
    "    )\n",
    "    ax.coastlines()\n",
    "    ax.set_title(f'IRI TEC {dt.strftime(\"%Y-%m-%d %H:%M UTC\")}')\n",
    "    plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Plot JPLD TEC\n",
    "    ax = axs[1]\n",
    "    im = ax.pcolormesh(lon, lat, jpld_tec, cmap='jet', vmin=0, vmax=np.percentile(iri_tec, 95), shading='auto')\n",
    "    ax.coastlines()\n",
    "    ax.set_title(f'JPLD TEC {dt.strftime(\"%Y-%m-%d %H:%M UTC\")}')\n",
    "    plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for the first IRI time\n",
    "i = 0\n",
    "iri_tec_map = all_tec[i][np.argmin(np.abs(iri_runs[i][\"ahr\"] - (iri_times[i]-datetime(iri_runs[i][\"year\"], iri_runs[i][\"month\"], iri_runs[i][\"day\"])).total_seconds()/3600))]\n",
    "iri_tec_map = np.rot90(iri_tec_map.reshape(alon_2d.shape))\n",
    "\n",
    "jpld_idx = matched_indices[i]\n",
    "jpld_tec_map = jpld_struct[\"tec\"][jpld_idx, :, :]\n",
    "\n",
    "plot_side_by_side(iri_tec_map, jpld_tec_map, jpld_struct[\"lat\"], jpld_struct[\"lon\"], iri_times[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the TEC maps into 1D arrays\n",
    "tec_iri_flat = iri_tec_map.flatten()\n",
    "tec_jpld_flat = jpld_tec_map.flatten()\n",
    "\n",
    "# Mask NaNs or negative values if needed\n",
    "mask = np.isfinite(tec_iri_flat) & np.isfinite(tec_jpld_flat) & (tec_iri_flat > 0) & (tec_jpld_flat > 0)\n",
    "tec_iri_clean = tec_iri_flat[mask]\n",
    "tec_jpld_clean = tec_jpld_flat[mask]\n",
    "\n",
    "# Create 2D histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "hb = plt.hist2d(\n",
    "    tec_iri_clean,\n",
    "    tec_jpld_clean,\n",
    "    bins=50,\n",
    "    norm=plt.cm.colors.LogNorm(),  # Log scale to emphasize spread\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "# Add colorbar and labels\n",
    "plt.colorbar(hb[3], label='Counts (log scale)')\n",
    "plt.xlabel('IRI TEC (TECU)')\n",
    "plt.ylabel('JPLD TEC (TECU)')\n",
    "plt.title('2D Histogram: IRI vs JPLD TEC')\n",
    "\n",
    "# Optional: add 1:1 line for reference\n",
    "min_val = min(tec_iri_clean.min(), tec_jpld_clean.min())\n",
    "max_val = max(tec_iri_clean.max(), tec_jpld_clean.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='1:1 line')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
