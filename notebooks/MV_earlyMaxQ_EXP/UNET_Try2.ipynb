{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b42f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d18ac27",
   "metadata": {},
   "source": [
    "Self contained UNET with comparisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Force non-interactive backend for animation safety!\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- CONFIG ---\n",
    "IONEX_PATHS = [\n",
    "    './ionosphere_central/vTEC_data/uqrg1000.24i',\n",
    "    './ionosphere_central/vTEC_data/uqrg1010.24i'\n",
    "]\n",
    "COMBINED_IONEX_PARQUET = \"combined_ionex_vtec.parquet\"\n",
    "TIEGCM_DIR = './ionosphere_central/CCMC/model_data/TIE-GCM/129/Akshay_Ramesh_042125_IT_5/'\n",
    "SPATIAL_FACTOR = 2\n",
    "TEMPORAL_MINUTES = 10\n",
    "\n",
    "# --- Parse IONEX Observations ---\n",
    "def parse_ionex_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    header_end = [i for i, l in enumerate(lines) if 'END OF HEADER' in l][0]\n",
    "    header = lines[:header_end]\n",
    "    for line in header:\n",
    "        if 'LAT1 / LAT2 / DLAT' in line:\n",
    "            lat1, lat2, dlat = map(float, line.split()[:3])\n",
    "        if 'LON1 / LON2 / DLON' in line:\n",
    "            lon1, lon2, dlon = map(float, line.split()[:3])\n",
    "    lats = np.arange(lat1, lat2 - 0.1, -abs(dlat))\n",
    "    lons = np.arange(lon1, lon2 + 0.1, dlon)\n",
    "    maps, epochs = [], []\n",
    "    i = header_end + 1\n",
    "    while i < len(lines):\n",
    "        if 'START OF TEC MAP' in lines[i]:\n",
    "            epoch_line = lines[i+1]\n",
    "            y, mo, d, h, mi, s = map(int, epoch_line[:36].split())\n",
    "            epoch = datetime(y, mo, d, h%24, mi, s) + timedelta(days=h//24)\n",
    "            epochs.append(epoch)\n",
    "            grid = []\n",
    "            i += 2\n",
    "            while 'END OF TEC MAP' not in lines[i]:\n",
    "                if 'LAT/LON1/LON2/DLON/H' in lines[i]:\n",
    "                    row = []\n",
    "                    i += 1\n",
    "                    while lines[i].strip() and 'LAT/LON1/LON2/DLON/H' not in lines[i] and 'END OF TEC MAP' not in lines[i]:\n",
    "                        line_values = re.findall(r'[-+]?[0-9]*\\.?[0-9]+', lines[i])\n",
    "                        vals = [float(v) if v != '9999' else np.nan for v in line_values]\n",
    "                        row.extend(vals)\n",
    "                        i += 1\n",
    "                    if len(row) == len(lons):\n",
    "                        grid.append(row)\n",
    "                else:\n",
    "                    i += 1\n",
    "            if len(grid) == len(lats):\n",
    "                maps.append(grid)\n",
    "        else:\n",
    "            i += 1\n",
    "    maps = np.array(maps)\n",
    "    data = {(lat, lon): maps[:, lat_idx, lon_idx] for lat_idx, lat in enumerate(lats) for lon_idx, lon in enumerate(lons)}\n",
    "    df = pd.DataFrame(data, index=epochs)\n",
    "    df = 0.1 * df  # Correction factor as requested\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['lat', 'lon'])\n",
    "    return df\n",
    "\n",
    "def load_obs_grid(paths, save_path=None):\n",
    "    dfs = []\n",
    "    for fp in paths:\n",
    "        if fp:\n",
    "            try:\n",
    "                dfs.append(parse_ionex_file(fp))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {fp}: {e}\")\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[~df.index.duplicated(keep='first')].sort_index()\n",
    "    if save_path:\n",
    "        df.to_parquet(save_path)\n",
    "    return df\n",
    "\n",
    "def load_model_grid(directory):\n",
    "    model_files = sorted([\n",
    "        f for f in os.listdir(directory)\n",
    "        if not f.endswith('.json')\n",
    "    ])\n",
    "    grids, times = [], []\n",
    "    lat0, lon0 = None, None\n",
    "    for fname in model_files:\n",
    "        fpath = os.path.join(directory, fname)\n",
    "        try:\n",
    "            try:\n",
    "                ds = xr.open_dataset(fpath, engine='netcdf4')\n",
    "            except Exception:\n",
    "                ds = xr.open_dataset(fpath, engine='scipy')\n",
    "            if 'TEC' not in ds.variables:\n",
    "                print(f\"Skipping {fname}: no 'TEC'\")\n",
    "                continue\n",
    "            tec = ds['TEC'].values\n",
    "            if lat0 is None:\n",
    "                lat0 = ds['lat'].values\n",
    "                lon0 = ds['lon'].values\n",
    "            if 'time' in ds:\n",
    "                tvals = pd.to_datetime(ds['time'].values)\n",
    "                for i in range(tec.shape[0]):\n",
    "                    grids.append(tec[i] / 1e12)\n",
    "                    times.append(tvals[i])\n",
    "            else:\n",
    "                grids.append(tec / 1e12)\n",
    "                times.append(None)\n",
    "            print(f\"Loaded {fname} shape {tec.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {fname}: {e}\")\n",
    "    if not grids:\n",
    "        raise RuntimeError(\"No valid model grids found! Please check files and data.\")\n",
    "    grids = np.stack(grids)\n",
    "    times = pd.to_datetime(times)\n",
    "    print(f\"Loaded {len(grids)} model grids, grid shape {grids.shape}\")\n",
    "    return grids, times, lat0, lon0\n",
    "\n",
    "def interpolate_to_grid(obs_grids, obs_lats, obs_lons, tgt_lats, tgt_lons):\n",
    "    out = []\n",
    "    for grid in obs_grids:\n",
    "        interp = RegularGridInterpolator((obs_lats, obs_lons), grid, bounds_error=False, fill_value=np.nan)\n",
    "        mesh = np.meshgrid(tgt_lats, tgt_lons, indexing='ij')\n",
    "        pts = np.stack([m.ravel() for m in mesh], axis=-1)\n",
    "        grid_interp = interp(pts).reshape(len(tgt_lats), len(tgt_lons))\n",
    "        out.append(grid_interp)\n",
    "    return np.stack(out)\n",
    "\n",
    "def interp_time(series_times, series_grids, new_times):\n",
    "    interp = interp1d([pd.Timestamp(t).timestamp() for t in series_times],\n",
    "                      series_grids, axis=0, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "    return interp([pd.Timestamp(t).timestamp() for t in new_times])\n",
    "\n",
    "def make_training_pairs(data, spatial_factor):\n",
    "    n, h, w = data.shape\n",
    "    X, Y = [], []\n",
    "    for i in range(n):\n",
    "        hr = data[i]\n",
    "        lr = resize(hr, (h//spatial_factor, w//spatial_factor), order=3, anti_aliasing=True)\n",
    "        up = resize(lr, (h, w), order=3, anti_aliasing=False)\n",
    "        X.append(up)\n",
    "        Y.append(hr)\n",
    "    X = np.stack(X)[..., None]\n",
    "    Y = np.stack(Y)[..., None]\n",
    "    return X, Y\n",
    "\n",
    "# --- MODELS (TF) ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    c1 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "    c2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "    m = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p2)\n",
    "    u2 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(m)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u2)\n",
    "    u1 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c3)\n",
    "    u1 = layers.concatenate([u1, c1])\n",
    "    c4 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(u1)\n",
    "    outputs = layers.Conv2D(1, (1,1), activation='linear', padding='same')(c4)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "def build_srcnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, 9, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(32, 1, padding='same', activation='relu')(x)\n",
    "    outputs = layers.Conv2D(1, 5, padding='same')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "def train_tf(model, X_train, Y_train, epochs=20, batch_size=8):\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "# --- PLOTTING & VERIFICATION ---\n",
    "def verify_and_plot_results(model_lats, model_lons, all_epochs, obs_interp, model_interp, Y_pred, out_prefix='comparison'):\n",
    "    vmin = np.nanmin([np.nanmin(obs_interp), np.nanmin(model_interp), np.nanmin(Y_pred)])\n",
    "    vmax = np.nanmax([np.nanmax(obs_interp), np.nanmax(model_interp), np.nanmax(Y_pred)])\n",
    "\n",
    "    idxs = np.linspace(0, len(all_epochs)-1, min(20, len(all_epochs))).astype(int)\n",
    "\n",
    "    # --- Static Example Comparison Plots ---\n",
    "    for i, idx in enumerate(idxs[:5]):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        titles = [\n",
    "            f\"Obs (Interp) {all_epochs[idx]:%Y-%m-%d %H:%M}\",\n",
    "            f\"Physical Model {all_epochs[idx]:%Y-%m-%d %H:%M}\",\n",
    "            f\"Super-Res Output {all_epochs[idx]:%Y-%m-%d %H:%M}\",\n",
    "        ]\n",
    "        data = [obs_interp[idx], model_interp[idx], Y_pred[idx][..., 0]]\n",
    "        for ax, dat, title in zip(axs, data, titles):\n",
    "            im = ax.pcolormesh(model_lons, model_lats, dat, vmin=vmin, vmax=vmax, shading='auto', cmap='plasma')\n",
    "            ax.coastlines()\n",
    "            ax.set_title(title)\n",
    "            cb = plt.colorbar(im, ax=ax, orientation='vertical')\n",
    "            cb.set_label('VTEC (TECU)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{out_prefix}_static_{i:02d}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- RMSE Time Series Plot ---\n",
    "    rmse_model = np.sqrt(np.nanmean((obs_interp - model_interp) ** 2, axis=(1, 2)))\n",
    "    rmse_sr = np.sqrt(np.nanmean((obs_interp - Y_pred[:obs_interp.shape[0],..., 0]) ** 2, axis=(1, 2)))\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(all_epochs, rmse_model, label='Physical Model', color='tab:blue')\n",
    "    ax.plot(all_epochs, rmse_sr, label='Super-Res', color='tab:orange')\n",
    "    ax.set_ylabel('RMSE (TECU)')\n",
    "    ax.set_title('RMSE of Model vs. Super-Res vs. Obs')\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{out_prefix}_rmse_timeseries.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- Global Error Map (Mean Absolute Error) ---\n",
    "    mae_model = np.nanmean(np.abs(obs_interp - model_interp), axis=0)\n",
    "    mae_sr = np.nanmean(np.abs(obs_interp - Y_pred[:obs_interp.shape[0],..., 0]), axis=0)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    for ax, dat, title in zip(axs, [mae_model, mae_sr], ['Physical Model MAE', 'Super-Res MAE']):\n",
    "        im = ax.pcolormesh(model_lons, model_lats, dat, shading='auto', cmap='inferno')\n",
    "        ax.coastlines()\n",
    "        ax.set_title(title)\n",
    "        cb = plt.colorbar(im, ax=ax, orientation='vertical')\n",
    "        cb.set_label('Mean Absolute Error (TECU)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{out_prefix}_mae_maps.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"Comparison plots saved.\")\n",
    "\n",
    "    # --- ANIMATION (Robust, no ax.clear, no memory leak) ---\n",
    "    def animate_panel(model_lats, model_lons, all_epochs, obs_interp, model_interp, Y_pred, out_prefix):\n",
    "        n_frames = obs_interp.shape[0]\n",
    "        vmin = np.nanmin([np.nanmin(obs_interp), np.nanmin(model_interp), np.nanmin(Y_pred)])\n",
    "        vmax = np.nanmax([np.nanmax(obs_interp), np.nanmax(model_interp), np.nanmax(Y_pred)])\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(21, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        titles = ['Obs (Interp)', 'Physical Model', 'Super-Res']\n",
    "        arrs = [obs_interp[0], model_interp[0], Y_pred[0][..., 0]]\n",
    "        meshes = []\n",
    "        for ax, arr, title in zip(axs, arrs, titles):\n",
    "            mesh = ax.pcolormesh(model_lons, model_lats, arr, vmin=vmin, vmax=vmax, shading='auto', cmap='plasma')\n",
    "            ax.coastlines()\n",
    "            ax.set_title(title)\n",
    "            cb = plt.colorbar(mesh, ax=ax, orientation='vertical')\n",
    "            cb.set_label('VTEC (TECU)')\n",
    "            meshes.append(mesh)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        def update(idx):\n",
    "            arrs = [obs_interp[idx], model_interp[idx], Y_pred[idx][..., 0]]\n",
    "            for mesh, arr in zip(meshes, arrs):\n",
    "                mesh.set_array(arr.ravel())\n",
    "            fig.suptitle(f'Global VTEC {all_epochs[idx]:%Y-%m-%d %H:%M}')\n",
    "            return meshes\n",
    "\n",
    "        ani = animation.FuncAnimation(fig, update, frames=n_frames, blit=False)\n",
    "        ani.save(f'{out_prefix}_compare.gif', writer='pillow', fps=5)\n",
    "        plt.close(fig)\n",
    "        print(f\"Animation saved to {out_prefix}_compare.gif\")\n",
    "\n",
    "    # Add this call at the end of verify_and_plot_results\n",
    "    animate_panel(model_lats, model_lons, all_epochs, obs_interp, model_interp, Y_pred, out_prefix)\n",
    "\n",
    "# --- MAIN ---\n",
    "def main(backend='tf', architecture='unet'):\n",
    "    obs_df = load_obs_grid(IONEX_PATHS, save_path=COMBINED_IONEX_PARQUET)\n",
    "    obs_lats = sorted(set([lat for lat, _ in obs_df.columns]))\n",
    "    obs_lons = sorted(set([lon for _, lon in obs_df.columns]))\n",
    "    obs_epochs = pd.to_datetime(obs_df.index)\n",
    "    obs_grids = np.stack([obs_df.loc[t].values.reshape((len(obs_lats), len(obs_lons))) for t in obs_df.index])\n",
    "\n",
    "    model_grids, model_times, model_lats, model_lons = load_model_grid(TIEGCM_DIR)\n",
    "    obs_on_model = interpolate_to_grid(obs_grids, obs_lats, obs_lons, model_lats, model_lons)\n",
    "    all_epochs = pd.date_range(start=max(obs_epochs[0], model_times[0]), end=min(obs_epochs[-1], model_times[-1]), freq=f'{TEMPORAL_MINUTES}min')\n",
    "    obs_interp = interp_time(obs_epochs, obs_on_model, all_epochs)\n",
    "    model_interp = interp_time(model_times, model_grids, all_epochs)\n",
    "    all_grids = np.concatenate([obs_interp, model_interp], axis=0)\n",
    "    mean, std = np.nanmean(all_grids), np.nanstd(all_grids)\n",
    "    all_grids = np.nan_to_num((all_grids - mean) / std)\n",
    "\n",
    "    X, Y = make_training_pairs(all_grids, SPATIAL_FACTOR)\n",
    "    if backend == 'tf':\n",
    "        if architecture == 'unet':\n",
    "            model = build_unet(input_shape=X.shape[1:])\n",
    "        elif architecture == 'srcnn':\n",
    "            model = build_srcnn(input_shape=X.shape[1:])\n",
    "        model = train_tf(model, X, Y, epochs=30)\n",
    "        Y_pred = model.predict(X)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only TensorFlow U-Net implemented here.\")\n",
    "\n",
    "    Y_pred = Y_pred * std + mean\n",
    "    N = obs_interp.shape[0]\n",
    "    Y_pred = Y_pred[:N]\n",
    "    model_interp = model_interp[:N]\n",
    "    all_epochs = all_epochs[:N]\n",
    "\n",
    "    verify_and_plot_results(\n",
    "        model_lats, model_lons, all_epochs, obs_interp, model_interp, Y_pred\n",
    "    )\n",
    "\n",
    "    np.save(\"superres_vtec.npy\", Y_pred)\n",
    "    print(\"Saved super-resolved output.\")\n",
    "\n",
    "# --- RUN ---\n",
    "if __name__ == '__main__':\n",
    "    main(backend='tf', architecture='unet')\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
