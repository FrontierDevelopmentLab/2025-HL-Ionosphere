{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942af73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4943920",
   "metadata": {},
   "source": [
    "This is the first attempt to model something.. and increase resolution to 4x and time to 5min timessteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef08870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.animation as animation\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "spatial_factor = 4 # increase resolution\n",
    "temporal_minutes = 5 # 5min timesteps\n",
    "model_directory = './ionosphere_central/CCMC/model_data/TIE-GCM/129/Akshay_Ramesh_042125_IT_5/'\n",
    "\n",
    "# --- LOAD OBSERVATIONAL DATA ---\n",
    "df = pd.read_parquet(\"combined_ionex_vtec.parquet\")\n",
    "df= df*0.035\n",
    "# --- LOAD MODEL DATA ---\n",
    "model_files = sorted([f for f in os.listdir(model_directory) if not f.endswith('.json')])\n",
    "model_grids, model_times = [], []\n",
    "for fname in model_files:\n",
    "    fpath = os.path.join(model_directory, fname)\n",
    "    try:\n",
    "        ds = xr.open_dataset(fpath)\n",
    "        if 'TEC' not in ds.variables:\n",
    "            print(f\"Skipping {fname} (no 'TEC' variable)\")\n",
    "            continue\n",
    "        tec = ds['TEC'].values\n",
    "        if 'time' in ds:\n",
    "            times = pd.to_datetime(ds['time'].values)\n",
    "            for i in range(tec.shape[0]):\n",
    "                model_grids.append(tec[i]/1e12)\n",
    "                model_times.append(times[i])\n",
    "        else:\n",
    "            model_grids.append(tec/1e12)\n",
    "            model_times.append(None)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fname}: {e}\")\n",
    "\n",
    "if len(model_grids) == 0:\n",
    "    raise RuntimeError(\"No valid model grids found! Please check files and data.\")\n",
    "\n",
    "model_grids = np.stack(model_grids)     # (n_times, lat, lon)\n",
    "model_times = pd.to_datetime([t if t is not None else pd.NaT for t in model_times])\n",
    "model_lats = ds['lat'].values\n",
    "model_lons = ds['lon'].values\n",
    "\n",
    "# --- PREP OBSERVATIONAL DATA ---\n",
    "lats = sorted(set([lat for lat, _ in df.columns]))\n",
    "lons = sorted(set([lon for _, lon in df.columns]))\n",
    "obs_epochs = pd.to_datetime(df.index)\n",
    "df = df.sort_index(axis=1, level=['lat', 'lon'])\n",
    "obs_grids = np.stack([df.loc[epoch].values.reshape((len(lats), len(lons))) for epoch in df.index], axis=0)\n",
    "\n",
    "# --- INTERPOLATE OBSERVATIONS ONTO MODEL GRID ---\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "obs_on_model = []\n",
    "for g in obs_grids:\n",
    "    interp_func = RegularGridInterpolator((lats, lons), g, bounds_error=False, fill_value=np.nan)\n",
    "    mesh = np.meshgrid(model_lats, model_lons, indexing='ij')\n",
    "    pts = np.column_stack([m.ravel() for m in mesh])\n",
    "    out = interp_func(pts).reshape(len(model_lats), len(model_lons))\n",
    "    obs_on_model.append(out)\n",
    "obs_on_model = np.stack(obs_on_model)   # (n_times, lat, lon)\n",
    "\n",
    "# --- SYNC TIME AXES: Interpolate obs/model to common set ---\n",
    "all_epochs = sorted(set(model_times.dropna()).union(set(obs_epochs)))\n",
    "all_epochs = pd.to_datetime(all_epochs)\n",
    "# Pad obs/model if needed with NaN grids\n",
    "def interp_time(series_times, series_grids, new_times):\n",
    "    series_times = pd.to_datetime(series_times)\n",
    "    keep = ~pd.isnull(series_times)\n",
    "    series_times = series_times[keep]\n",
    "    series_grids = series_grids[keep]\n",
    "    # In case only 1 grid, just tile it\n",
    "    if len(series_grids) == 1:\n",
    "        arr = np.repeat(series_grids, len(new_times), axis=0)\n",
    "        return arr\n",
    "    interp = interp1d(\n",
    "        [pd.Timestamp(t).timestamp() for t in series_times],\n",
    "        series_grids, axis=0, kind='linear', bounds_error=False, fill_value=\"extrapolate\"\n",
    "    )\n",
    "    return interp([pd.Timestamp(t).timestamp() for t in new_times])\n",
    "\n",
    "obs_interp = interp_time(obs_epochs, obs_on_model, all_epochs)\n",
    "model_interp = interp_time(model_times, model_grids, all_epochs)\n",
    "\n",
    "# --- CONCATENATE FOR TRAINING DATASET ---\n",
    "all_grids = np.concatenate([obs_interp, model_interp], axis=0)\n",
    "np.random.shuffle(all_grids)\n",
    "mean = np.nanmean(all_grids)\n",
    "std = np.nanstd(all_grids)\n",
    "all_grids_norm = (all_grids - mean) / std\n",
    "all_grids_norm = np.nan_to_num(all_grids_norm)\n",
    "\n",
    "# --- GENERATE TRAINING PAIRS (LOWRES -> UPSAMPLED, TARGET=SUPERRES) ---\n",
    "X_train, Y_train = [], []\n",
    "n_lat, n_lon = all_grids_norm.shape[1:3]\n",
    "for i in range(all_grids_norm.shape[0]):\n",
    "    lowres = resize(all_grids_norm[i], (n_lat//spatial_factor, n_lon//spatial_factor), order=3, anti_aliasing=True)\n",
    "    upsampled = resize(lowres, (n_lat*spatial_factor, n_lon*spatial_factor), order=3, anti_aliasing=False)\n",
    "    target = resize(all_grids_norm[i], (n_lat*spatial_factor, n_lon*spatial_factor), order=3, anti_aliasing=True)\n",
    "    X_train.append(upsampled)\n",
    "    Y_train.append(target)\n",
    "X_train = np.stack(X_train)\n",
    "Y_train = np.stack(Y_train)\n",
    "X_train = torch.tensor(X_train[:,None,:,:], dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train[:,None,:,:], dtype=torch.float32)\n",
    "\n",
    "# --- DEFINE SRCNN MODEL ---\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_filters=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, num_filters, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters//2, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(num_filters//2, out_channels, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# --- TRAIN SRCNN ---\n",
    "model = SRCNN().cuda() if torch.cuda.is_available() else SRCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs_train = 11\n",
    "for epoch in range(epochs_train):\n",
    "    perm = torch.randperm(X_train.shape[0])\n",
    "    for idx in tqdm(perm, desc=f\"Epoch {epoch+1}/{epochs_train}\"):\n",
    "        inp = X_train[idx:idx+1]\n",
    "        tgt = Y_train[idx:idx+1]\n",
    "        if torch.cuda.is_available():\n",
    "            inp, tgt = inp.cuda(), tgt.cuda()\n",
    "        out = model(inp)\n",
    "        loss = loss_fn(out, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.5f}\")\n",
    "\n",
    "# --- INFERENCE: SUPER-RESOLVE ALL TIMES ---\n",
    "up_lats = np.linspace(min(model_lats), max(model_lats), n_lat*spatial_factor)\n",
    "up_lons = np.linspace(min(model_lons), max(model_lons), n_lon*spatial_factor)\n",
    "hr_grids = []\n",
    "hr_grid_times = []\n",
    "model.eval()\n",
    "for i, grid in enumerate(all_grids_norm):\n",
    "    lowres = resize(grid, (n_lat//spatial_factor, n_lon//spatial_factor), order=3, anti_aliasing=True)\n",
    "    upsampled = resize(lowres, (n_lat*spatial_factor, n_lon*spatial_factor), order=3, anti_aliasing=False)\n",
    "    inp = torch.tensor(upsampled[None,None,:,:], dtype=torch.float32)\n",
    "    if torch.cuda.is_available():\n",
    "        inp = inp.cuda()\n",
    "    with torch.no_grad():\n",
    "        out = model(inp).cpu().numpy()[0,0]\n",
    "    grid_hr = out * std + mean\n",
    "    hr_grids.append(grid_hr)\n",
    "    # The time associated with this grid:\n",
    "    if i < len(all_epochs):\n",
    "        hr_grid_times.append(all_epochs[i])\n",
    "    else:\n",
    "        hr_grid_times.append(pd.NaT)\n",
    "hr_grids = np.stack(hr_grids)\n",
    "hr_grid_times = pd.to_datetime(hr_grid_times)\n",
    "\n",
    "# --- TEMPORAL INTERPOLATION TO EVERY 5 MIN ---\n",
    "# Use only non-NaT times and associated grids for interpolation\n",
    "valid_idx = ~pd.isnull(hr_grid_times)\n",
    "hr_grids_valid = hr_grids[valid_idx]\n",
    "hr_times_valid = hr_grid_times[valid_idx]\n",
    "\n",
    "all_times = pd.date_range(start=hr_times_valid[0], end=hr_times_valid[-1], freq=f'{temporal_minutes}min')\n",
    "if len(hr_grids_valid) == 1:\n",
    "    all_hr_grids = np.repeat(hr_grids_valid, len(all_times), axis=0)\n",
    "else:\n",
    "    interp_func = interp1d(\n",
    "        [pd.Timestamp(t).timestamp() for t in hr_times_valid],\n",
    "        hr_grids_valid, axis=0, kind='linear', bounds_error=False, fill_value=\"extrapolate\"\n",
    "    )\n",
    "    all_hr_grids = interp_func([pd.Timestamp(t).timestamp() for t in all_times])\n",
    "\n",
    "# --- OUTPUT MODEL & RESULTS ---\n",
    "torch.save(model.state_dict(), \"superres_tec_srcnn.pt\")\n",
    "np.save(\"superres_tec_5min.npy\", all_hr_grids)\n",
    "print(f\"Model and super-resolved TEC saved. Shape: {all_hr_grids.shape}\")\n",
    "\n",
    "# --- OPTIONAL: ANIMATION (FLAT AND ORTHOGRAPHIC) ---\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "fig1, ax1 = plt.subplots(figsize=(12,6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "im1 = ax1.pcolormesh(up_lons, up_lats, all_hr_grids[0], transform=ccrs.PlateCarree(), shading='auto')\n",
    "cb1 = plt.colorbar(im1, ax=ax1, orientation='vertical', label='TEC (TECU)')\n",
    "def update1(idx):\n",
    "    im1.set_array(all_hr_grids[idx].ravel())\n",
    "    ax1.set_title(f'Super-Resolved TEC {all_times[idx]}')\n",
    "    return [im1]\n",
    "ani1 = animation.FuncAnimation(fig1, update1, frames=len(all_times), interval=100, blit=False)\n",
    "ani1.save('superres_tec_flat.gif', writer='pillow', fps=10)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(8,8))\n",
    "ax2 = plt.axes(projection=ccrs.Orthographic(central_longitude=0))\n",
    "im2 = ax2.pcolormesh(up_lons, up_lats, all_hr_grids[0], transform=ccrs.PlateCarree(), shading='auto')\n",
    "cb2 = plt.colorbar(im2, ax=ax2, orientation='vertical', label='TEC (TECU)')\n",
    "def update2(idx):\n",
    "    im2.set_array(all_hr_grids[idx].ravel())\n",
    "    ax2.set_title(f'Super-Resolved TEC {all_times[idx]}')\n",
    "    return [im2]\n",
    "ani2 = animation.FuncAnimation(fig2, update2, frames=len(all_times), interval=100, blit=False)\n",
    "ani2.save('superres_tec_ortho.gif', writer='pillow', fps=10)\n",
    "plt.close(fig2)\n",
    "\n",
    "print(\"Animations saved: Correctedsuperres_tec_flat.gif, Correctedsuperres_tec_ortho.gif\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
