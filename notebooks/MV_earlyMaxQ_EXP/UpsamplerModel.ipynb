{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ed2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.animation as animation\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "spatial_factor = 4\n",
    "temporal_minutes = 5\n",
    "model_directory = './ionosphere_central/CCMC/model_data/TIE-GCM/129/Akshay_Ramesh_042125_IT_5/'\n",
    "\n",
    "# --- LOAD MODEL DATA ---\n",
    "model_files = sorted([f for f in os.listdir(model_directory) if not f.endswith('.json')])\n",
    "model_grids, model_times = [], []\n",
    "for fname in model_files:\n",
    "    fpath = os.path.join(model_directory, fname)\n",
    "    try:\n",
    "        ds = xr.open_dataset(fpath)\n",
    "        if 'TEC' not in ds.variables:\n",
    "            print(f\"Skipping {fname} (no 'TEC' variable)\")\n",
    "            continue\n",
    "        tec = ds['TEC'].values\n",
    "        if 'time' in ds:\n",
    "            times = pd.to_datetime(ds['time'].values)\n",
    "            for i in range(tec.shape[0]):\n",
    "                model_grids.append(tec[i]/1e12)  # Already TECU (if not, adjust scale here)\n",
    "                model_times.append(times[i])\n",
    "        else:\n",
    "            model_grids.append(tec/1e12)\n",
    "            model_times.append(None)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fname}: {e}\")\n",
    "\n",
    "if len(model_grids) == 0:\n",
    "    raise RuntimeError(\"No valid model grids found! Please check files and data.\")\n",
    "\n",
    "model_grids = np.stack(model_grids)     # (n_times, lat, lon)\n",
    "model_times = pd.to_datetime([t if t is not None else pd.NaT for t in model_times])\n",
    "model_lats = ds['lat'].values\n",
    "model_lons = ds['lon'].values\n",
    "\n",
    "# --- LOAD & PREP OBSERVATION DATA ---\n",
    "df = pd.read_parquet(\"combined_ionex_vtec.parquet\")\n",
    "df = .035 * df\n",
    "lats = sorted(set([lat for lat, _ in df.columns]))\n",
    "lons = sorted(set([lon for _, lon in df.columns]))\n",
    "obs_epochs = pd.to_datetime(df.index)\n",
    "df = df.sort_index(axis=1, level=['lat', 'lon'])\n",
    "obs_grids = np.stack([df.loc[epoch].values.reshape((len(lats), len(lons))) for epoch in df.index], axis=0)\n",
    "\n",
    "# --- UNIT CONVERSION FOR OBSERVATIONS (if needed) ---\n",
    "if np.nanmax(obs_grids) > 200:  # Likely in 1e16 el/mÂ²\n",
    "    print(\"Converting obs_grids from VTEC units to TECU\")\n",
    "    obs_grids = obs_grids / 1e16  # Now in TECU\n",
    "\n",
    "# --- INTERPOLATE OBS ONTO MODEL GRID ---\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "obs_on_model = []\n",
    "for g in obs_grids:\n",
    "    interp_func = RegularGridInterpolator((lats, lons), g, bounds_error=False, fill_value=np.nan)\n",
    "    mesh = np.meshgrid(model_lats, model_lons, indexing='ij')\n",
    "    pts = np.column_stack([m.ravel() for m in mesh])\n",
    "    out = interp_func(pts).reshape(len(model_lats), len(model_lons))\n",
    "    obs_on_model.append(out)\n",
    "obs_on_model = np.stack(obs_on_model)   # (n_obs_times, lat, lon)\n",
    "\n",
    "# --- CHOOSE UNION TIME AXIS & INTERPOLATE TO 5-MIN ---\n",
    "min_time = max(np.nanmin(model_times), np.nanmin(obs_epochs))\n",
    "max_time = min(np.nanmax(model_times), np.nanmax(obs_epochs))\n",
    "all_times = pd.date_range(start=min_time, end=max_time, freq=f'{temporal_minutes}min')\n",
    "\n",
    "def interp_time(series_times, series_grids, new_times):\n",
    "    series_times = pd.to_datetime(series_times)\n",
    "    keep = ~pd.isnull(series_times)\n",
    "    series_times = np.array(series_times)[keep]\n",
    "    series_grids = np.array(series_grids)[keep]\n",
    "    # Remove times with NaN-only grids (fully missing)\n",
    "    keep2 = [not np.all(np.isnan(g)) for g in series_grids]\n",
    "    series_times = series_times[keep2]\n",
    "    series_grids = series_grids[keep2]\n",
    "    interp = interp1d(\n",
    "        [pd.Timestamp(t).timestamp() for t in series_times],\n",
    "        series_grids, axis=0, kind='linear', bounds_error=False, fill_value=\"extrapolate\"\n",
    "    )\n",
    "    return interp([pd.Timestamp(t).timestamp() for t in new_times])\n",
    "\n",
    "obs_interp = interp_time(obs_epochs, obs_on_model, all_times)\n",
    "model_interp = interp_time(model_times, model_grids, all_times)\n",
    "\n",
    "print(\"\\nDIAGNOSTICS:\")\n",
    "print(\"Obs Interp min/max/mean:\", np.nanmin(obs_interp), np.nanmax(obs_interp), np.nanmean(obs_interp))\n",
    "print(\"Model Interp min/max/mean:\", np.nanmin(model_interp), np.nanmax(model_interp), np.nanmean(model_interp))\n",
    "print(\"Obs shape:\", obs_interp.shape, \"Model shape:\", model_interp.shape)\n",
    "\n",
    "# --- SUPER-RESOLUTION TRAINING PAIRS ---\n",
    "all_grids = np.concatenate([obs_interp, model_interp], axis=0)\n",
    "mean = np.nanmean(all_grids)\n",
    "std = np.nanstd(all_grids)\n",
    "all_grids_norm = (all_grids - mean) / std\n",
    "all_grids_norm = np.nan_to_num(all_grids_norm)\n",
    "\n",
    "n_lat, n_lon = all_grids_norm.shape[1:3]\n",
    "X_train, Y_train = [], []\n",
    "for i in range(all_grids_norm.shape[0]):\n",
    "    lowres = resize(all_grids_norm[i], (n_lat//spatial_factor, n_lon//spatial_factor), order=3, anti_aliasing=True)\n",
    "    upsampled = resize(lowres, (n_lat*spatial_factor, n_lon*spatial_factor), order=3, anti_aliasing=False)\n",
    "    target = resize(all_grids_norm[i], (n_lat*spatial_factor, n_lon*spatial_factor), order=3, anti_aliasing=True)\n",
    "    X_train.append(upsampled)\n",
    "    Y_train.append(target)\n",
    "X_train = np.stack(X_train)\n",
    "Y_train = np.stack(Y_train)\n",
    "X_train = torch.tensor(X_train[:,None,:,:], dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train[:,None,:,:], dtype=torch.float32)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "# --- OPTIONAL: ANIMATION FOR VALIDATION ---\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "vmin = min(np.nanmin(obs_interp), np.nanmin(model_interp))\n",
    "vmax = max(np.nanmax(obs_interp), np.nanmax(model_interp))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "titles = [\"Obs (Interpolated)\", \"TIE-GCM Model (Interpolated)\"]\n",
    "for ax, title in zip(axes, titles):\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "    ax.set_title(title)\n",
    "\n",
    "im_obs = axes[0].pcolormesh(model_lons, model_lats, obs_interp[0], transform=ccrs.PlateCarree(),\n",
    "                            shading='auto', vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "im_mod = axes[1].pcolormesh(model_lons, model_lats, model_interp[0], transform=ccrs.PlateCarree(),\n",
    "                            shading='auto', vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "\n",
    "cb = fig.colorbar(im_obs, ax=axes, orientation='horizontal', fraction=0.04, pad=0.09, label='TEC (TECU)')\n",
    "\n",
    "def update(idx):\n",
    "    im_obs.set_array(obs_interp[idx].ravel())\n",
    "    im_mod.set_array(model_interp[idx].ravel())\n",
    "    axes[0].set_title(f\"Obs (Interp)\\n{all_times[idx]}\")\n",
    "    axes[1].set_title(f\"Model (Interp)\\n{all_times[idx]}\")\n",
    "    return [im_obs, im_mod]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(all_times), interval=100, blit=False)\n",
    "ani.save('obs_vs_model_5min.gif', writer='pillow', fps=10)\n",
    "plt.close(fig)\n",
    "print(\"Saved synchronized validation animation: obs_vs_model_5min.gif\")\n",
    "\n",
    "# --- DATA READY FOR ML ---\n",
    "print(\"Ready for super-resolution training with PyTorch or TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c947c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# If you have [N, 1, H, W], squeeze the singleton channel for Keras [N, H, W, 1]\n",
    "X = np.load('X_train.npy') if os.path.exists('X_train.npy') else X_train.numpy()\n",
    "Y = np.load('Y_train.npy') if os.path.exists('Y_train.npy') else Y_train.numpy()\n",
    "X = np.squeeze(X) if X.shape[1] == 1 else X\n",
    "Y = np.squeeze(Y) if Y.shape[1] == 1 else Y\n",
    "\n",
    "# Keras wants channel-last: [N, H, W, 1]\n",
    "X = X[..., None]\n",
    "Y = Y[..., None]\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c549030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_upsampler(input_shape, base_filters=32):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(base_filters, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(base_filters, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = layers.Conv2D(base_filters*2, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(base_filters*2, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "    # Bottleneck\n",
    "    b = layers.Conv2D(base_filters*4, 3, activation='relu', padding='same')(p2)\n",
    "    b = layers.Conv2D(base_filters*4, 3, activation='relu', padding='same')(b)\n",
    "    # Decoder\n",
    "    u2 = layers.UpSampling2D()(b)\n",
    "    concat2 = layers.Concatenate()([u2, c2])\n",
    "    d2 = layers.Conv2D(base_filters*2, 3, activation='relu', padding='same')(concat2)\n",
    "    d2 = layers.Conv2D(base_filters*2, 3, activation='relu', padding='same')(d2)\n",
    "    u1 = layers.UpSampling2D()(d2)\n",
    "    concat1 = layers.Concatenate()([u1, c1])\n",
    "    d1 = layers.Conv2D(base_filters, 3, activation='relu', padding='same')(concat1)\n",
    "    d1 = layers.Conv2D(base_filters, 3, activation='relu', padding='same')(d1)\n",
    "    # Final convolution\n",
    "    outputs = layers.Conv2D(1, 1, activation='linear', padding='same')(d1)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Example: input lowres upsampled (n_lat*sf, n_lon*sf, 1), output target highres\n",
    "input_shape = X.shape[1:]  # e.g. (n_lat*sf, n_lon*sf, 1)\n",
    "model = unet_upsampler(input_shape, base_filters=32)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ac3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Optionally, split into train/val\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xval, Ytr, Yval = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=8, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_upsampler_unet.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    Xtr, Ytr,\n",
    "    validation_data=(Xval, Yval),\n",
    "    batch_size=8,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a53bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set (or any batch)\n",
    "Y_pred = model.predict(Xval)\n",
    "print(\"Y_pred shape:\", Y_pred.shape)\n",
    "\n",
    "# Example plot for the first validation sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 0  # first sample\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(Xval[i, ..., 0], aspect='auto')\n",
    "axs[0].set_title('Input (Low-res upsampled)')\n",
    "axs[1].imshow(Yval[i, ..., 0], aspect='auto')\n",
    "axs[1].set_title('Target (High-res)')\n",
    "axs[2].imshow(Y_pred[i, ..., 0], aspect='auto')\n",
    "axs[2].set_title('Prediction (Super-res)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"validation_example.png\")  # <-- Save the figure as PNG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_upsampler_unet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# 1. Check your original model input shape:\n",
    "expected_shape = upsampler.input_shape  # (None, h, w, 1)\n",
    "_, n_lat, n_lon, n_chan = expected_shape\n",
    "print(\"Model expects:\", expected_shape)\n",
    "\n",
    "# 2. If your model_interp is (time, orig_lat, orig_lon), upsample it:\n",
    "spatial_factor = n_lat // model_interp.shape[1]\n",
    "print(\"Spatial upsample factor:\", spatial_factor)\n",
    "\n",
    "model_up = []\n",
    "for t in range(model_interp.shape[0]):\n",
    "    upsampled = resize(\n",
    "        model_interp[t], (n_lat, n_lon),\n",
    "        order=3, anti_aliasing=True, preserve_range=True\n",
    "    )\n",
    "    model_up.append(upsampled)\n",
    "model_up = np.stack(model_up)  # (time, n_lat, n_lon)\n",
    "\n",
    "# 3. Add channel dim\n",
    "model_in = model_up[..., np.newaxis]  # (time, n_lat, n_lon, 1)\n",
    "\n",
    "# 4. Predict\n",
    "superres = upsampler.predict(model_in, verbose=1)\n",
    "superres = np.squeeze(superres)\n",
    "print(\"Superres shape:\", superres.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "# --- Make sure you have these variables: ---\n",
    "# superres: (T, new_lat, new_lon)\n",
    "# model_lats, model_lons: original grids (1D)\n",
    "# all_times or times_for_sr: (T,) datetime array matching superres\n",
    "\n",
    "# If needed:\n",
    "# times_for_sr = all_times\n",
    "\n",
    "# --- Construct new (upsampled) lat/lon grid ---\n",
    "upsampled_lats = np.linspace(model_lats.min(), model_lats.max(), superres.shape[1])\n",
    "upsampled_lons = np.linspace(model_lons.min(), model_lons.max(), superres.shape[2])\n",
    "\n",
    "assert superres.shape[0] == len(times_for_sr), f\"Time axis and frames out of sync: {superres.shape[0]} vs {len(times_for_sr)}\"\n",
    "\n",
    "# --- Animation setup ---\n",
    "fig, ax = plt.subplots(figsize=(12, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax.set_global()\n",
    "ax.coastlines(resolution='110m', linewidth=1)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.7, edgecolor='gray')\n",
    "ax.add_feature(cfeature.LAND, zorder=0, edgecolor='black', alpha=0.1)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.2)\n",
    "ax.add_feature(cfeature.RIVERS, alpha=0.2)\n",
    "ax.set_title(\"Super-resolved TEC (Model)\")\n",
    "\n",
    "vmin, vmax = np.nanmin(superres), np.nanmax(superres)\n",
    "im = ax.pcolormesh(\n",
    "    upsampled_lons, upsampled_lats, superres[0],\n",
    "    cmap='viridis', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree()\n",
    ")\n",
    "cb = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.08, label='TEC (TECU)')\n",
    "\n",
    "def update_sr(i):\n",
    "    im.set_array(superres[i].ravel())\n",
    "    ax.set_title(f\"Super-resolved TEC (Model)\\n{times_for_sr[i]}\")\n",
    "    return [im]\n",
    "\n",
    "ani_sr = animation.FuncAnimation(\n",
    "    fig, update_sr, frames=superres.shape[0], interval=150, blit=False\n",
    ")\n",
    "ani_sr.save('model_superres.gif', writer='pillow', fps=8)\n",
    "plt.close(fig)\n",
    "print(\"Saved super-resolved model animation: model_superres.gif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.animation as animation\n",
    "from scipy.interpolate import RegularGridInterpolator, interp1d\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "\n",
    "# --- LOAD OBSERVATIONAL DATA ---\n",
    "df = pd.read_parquet(\"combined_ionex_vtec.parquet\")\n",
    "df = df * 0.04\n",
    "lats = sorted(set([lat for lat, _ in df.columns]))\n",
    "lons = sorted(set([lon for _, lon in df.columns]))\n",
    "obs_epochs = pd.to_datetime(df.index)\n",
    "df = df.sort_index(axis=1, level=['lat', 'lon'])\n",
    "obs_grids = np.stack([df.loc[epoch].values.reshape((len(lats), len(lons))) for epoch in df.index], axis=0)\n",
    "if np.nanmax(obs_grids) > 200: obs_grids = obs_grids / 1e16\n",
    "\n",
    "# --- LOAD MODEL DATA ---\n",
    "model_directory = './ionosphere_central/CCMC/model_data/TIE-GCM/129/Akshay_Ramesh_042125_IT_5/'\n",
    "model_files = sorted([f for f in os.listdir(model_directory) if not f.endswith('.json')])\n",
    "\n",
    "model_grids, model_times = [], []\n",
    "for fname in model_files:\n",
    "    fpath = os.path.join(model_directory, fname)\n",
    "    try:\n",
    "        ds = xr.open_dataset(fpath)\n",
    "        if 'TEC' not in ds.variables:\n",
    "            print(f\"Skipping {fname} (no 'TEC' variable)\")\n",
    "            continue\n",
    "        tec = ds['TEC'].values\n",
    "        if 'time' in ds:\n",
    "            times = pd.to_datetime(ds['time'].values)\n",
    "            for i in range(tec.shape[0]):\n",
    "                model_grids.append(tec[i]/1e12)  # Convert to TECU if data is in 1e12 el/m^2\n",
    "                model_times.append(times[i])\n",
    "        else:\n",
    "            model_grids.append(tec/1e12)\n",
    "            model_times.append(None)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fname}: {e}\")\n",
    "\n",
    "if len(model_grids) == 0:\n",
    "    raise RuntimeError(\"No valid model grids found! Please check files and data.\")\n",
    "\n",
    "model_grids = np.stack(model_grids)     # (n_times, lat, lon)\n",
    "model_times = pd.to_datetime([t if t is not None else pd.NaT for t in model_times])\n",
    "model_lats = ds['lat'].values\n",
    "model_lons = ds['lon'].values\n",
    "\n",
    "# --- INTERPOLATE OBSERVATIONS ONTO MODEL GRID ---\n",
    "obs_on_model = []\n",
    "for g in obs_grids:\n",
    "    interp_func = RegularGridInterpolator((lats, lons), g, bounds_error=False, fill_value=np.nan)\n",
    "    mesh = np.meshgrid(model_lats, model_lons, indexing='ij')\n",
    "    pts = np.column_stack([m.ravel() for m in mesh])\n",
    "    out = interp_func(pts).reshape(len(model_lats), len(model_lons))\n",
    "    obs_on_model.append(out)\n",
    "obs_on_model = np.stack(obs_on_model)   # (n_obs_times, lat, lon)\n",
    "\n",
    "# --- SYNC TIME AXES: Interpolate both datasets to the same time axis ---\n",
    "common_times = sorted(set(model_times.dropna()).intersection(set(obs_epochs)))\n",
    "if len(common_times) == 0:\n",
    "    raise RuntimeError(\"No overlapping times found between obs and model!\")\n",
    "common_times = pd.to_datetime(common_times)\n",
    "def interp_time(series_times, series_grids, new_times):\n",
    "    series_times = pd.to_datetime(series_times)\n",
    "    keep = ~pd.isnull(series_times)\n",
    "    series_times = series_times[keep]\n",
    "    series_grids = series_grids[keep]\n",
    "    if len(series_grids) == 1:\n",
    "        arr = np.repeat(series_grids, len(new_times), axis=0)\n",
    "        return arr\n",
    "    interp = interp1d(\n",
    "        [pd.Timestamp(t).timestamp() for t in series_times],\n",
    "        series_grids, axis=0, kind='linear', bounds_error=False, fill_value=\"extrapolate\"\n",
    "    )\n",
    "    return interp([pd.Timestamp(t).timestamp() for t in new_times])\n",
    "obs_interp = interp_time(obs_epochs, obs_on_model, common_times)\n",
    "model_interp = interp_time(model_times, model_grids, common_times)\n",
    "\n",
    "# --- USE YOUR UPSAMPLER TO PRODUCE SUPERRES ---\n",
    "upsampler = tf.keras.models.load_model('final_upsampler_unet.h5', compile=False)\n",
    "upsampler.compile(optimizer='adam', loss='mse')\n",
    "_, h, w, c = upsampler.input_shape\n",
    "print(f\"Superres model expects: {(h, w)} spatial, {c} channels\")\n",
    "\n",
    "# --- Upsample model_interp to (h, w) as model input ---\n",
    "model_up = []\n",
    "for t in range(model_interp.shape[0]):\n",
    "    upsampled = resize(model_interp[t], (h, w), order=3, anti_aliasing=True, preserve_range=True)\n",
    "    model_up.append(upsampled)\n",
    "model_up = np.stack(model_up)\n",
    "model_up = model_up[..., np.newaxis]  # (frames, h, w, 1)\n",
    "\n",
    "# --- Run the upsampler ---\n",
    "superres = upsampler.predict(model_up, verbose=1)\n",
    "superres = np.squeeze(superres)  # (frames, h, w)\n",
    "\n",
    "# --- Upsample obs_interp to superres grid for direct comparison ---\n",
    "upsampled_lats = np.linspace(model_lats.min(), model_lats.max(), h)\n",
    "upsampled_lons = np.linspace(model_lons.min(), model_lons.max(), w)\n",
    "obs_up = []\n",
    "for arr in obs_interp:\n",
    "    interp_func = RegularGridInterpolator((model_lats, model_lons), arr, bounds_error=False, fill_value=np.nan)\n",
    "    mesh = np.meshgrid(upsampled_lats, upsampled_lons, indexing='ij')\n",
    "    pts = np.column_stack([m.ravel() for m in mesh])\n",
    "    up = interp_func(pts).reshape(h, w)\n",
    "    obs_up.append(up)\n",
    "obs_up = np.stack(obs_up)\n",
    "\n",
    "# --- For visualization, also upsample model_interp (to compare true model at superres grid) ---\n",
    "model_up_vis = model_up[...,0]  # (frames, h, w)\n",
    "\n",
    "# --- ANIMATION SETUP (4-PANEL: Obs, Model, Superres, Diff) ---\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "titles = [\n",
    "    \"Observations (upsampled)\", \n",
    "    \"TIE-GCM Model (upsampled)\", \n",
    "    \"Super-resolved Model\", \n",
    "    \"Difference (Superres - Obs)\"\n",
    "]\n",
    "diff_sr_obs = superres - obs_up\n",
    "vmin = np.nanmin([obs_up, model_up_vis, superres])\n",
    "vmax = np.nanmax([obs_up, model_up_vis, superres])\n",
    "abs_max_diff = np.nanmax(np.abs(diff_sr_obs))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(28, 7), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ims = []\n",
    "for i, (ax, title) in enumerate(zip(axes, titles)):\n",
    "    ax.set_global()\n",
    "    ax.coastlines(resolution='110m', linewidth=1)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.7, edgecolor='gray')\n",
    "    ax.add_feature(cfeature.LAND, zorder=0, edgecolor='black', alpha=0.1)\n",
    "    ax.set_title(title)\n",
    "    if i < 3:\n",
    "        ims.append(ax.pcolormesh(upsampled_lons, upsampled_lats, [obs_up, model_up_vis, superres][i][0],\n",
    "                                 cmap='viridis', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree()))\n",
    "    else:\n",
    "        ims.append(ax.pcolormesh(upsampled_lons, upsampled_lats, diff_sr_obs[0],\n",
    "                                 cmap='bwr', vmin=-abs_max_diff, vmax=abs_max_diff, shading='auto', transform=ccrs.PlateCarree()))\n",
    "cb = fig.colorbar(ims[0], ax=axes[:3], orientation='horizontal', pad=0.09, label='TEC (TECU)', fraction=0.04)\n",
    "cb_diff = fig.colorbar(ims[3], ax=axes[3], orientation='horizontal', pad=0.09, label='Superres - Obs (TECU)', fraction=0.04)\n",
    "\n",
    "def update_all(i):\n",
    "    ims[0].set_array(obs_up[i].ravel())\n",
    "    ims[1].set_array(model_up_vis[i].ravel())\n",
    "    ims[2].set_array(superres[i].ravel())\n",
    "    ims[3].set_array(diff_sr_obs[i].ravel())\n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.set_title(f\"{titles[idx]}\\n{common_times[i]}\")\n",
    "    return ims\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update_all, frames=superres.shape[0], interval=150, blit=False)\n",
    "ani.save('obs_vs_model_vs_superres_vs_diff.gif', writer='pillow', fps=8)\n",
    "plt.close(fig)\n",
    "print(\"\\nSaved 4-panel animation: obs_vs_model_vs_superres_vs_diff.gif\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
