{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d3cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ada9e762",
   "metadata": {},
   "source": [
    "This code loads files, and gets them ready for experiment. The data used in this first part is the ground based measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === LIST YOUR FILES HERE (up to 3, or fewer) ===\n",
    "file_paths = [\n",
    "    './ionosphere_central/vTEC_data/uqrg1000.24i',\n",
    "    './ionosphere_central/vTEC_data/uqrg1010.24i'\n",
    "]\n",
    "# Empty strings or missing files will be skipped\n",
    "\n",
    "def parse_ionex_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header_end = [i for i, l in enumerate(lines) if 'END OF HEADER' in l][0]\n",
    "    header = lines[:header_end]\n",
    "\n",
    "    for line in header:\n",
    "        if 'LAT1 / LAT2 / DLAT' in line:\n",
    "            lat1, lat2, dlat = map(float, line.split()[:3])\n",
    "        if 'LON1 / LON2 / DLON' in line:\n",
    "            lon1, lon2, dlon = map(float, line.split()[:3])\n",
    "\n",
    "    lats = np.arange(lat1, lat2 - 0.1, -abs(dlat))  # top-to-bottom\n",
    "    lons = np.arange(lon1, lon2 + 0.1, dlon)\n",
    "\n",
    "    maps = []\n",
    "    epochs = []\n",
    "    i = header_end + 1\n",
    "    while i < len(lines):\n",
    "        if 'START OF TEC MAP' in lines[i]:\n",
    "            epoch_line = lines[i+1]\n",
    "            y, mo, d, h, mi, s = map(int, epoch_line[:36].split())\n",
    "            if h == 24:\n",
    "                h = 0\n",
    "                base_date = datetime(y, mo, d) + timedelta(days=1)\n",
    "                epoch = datetime(base_date.year, base_date.month, base_date.day, h, mi, s)\n",
    "            else:\n",
    "                epoch = datetime(y, mo, d, h, mi, s)\n",
    "            epochs.append(epoch)\n",
    "\n",
    "            grid = []\n",
    "            i += 2\n",
    "            while i < len(lines) and ('START OF TEC MAP' not in lines[i]) and ('END OF FILE' not in lines[i]):\n",
    "                if 'LAT/LON1/LON2/DLON/H' in lines[i]:\n",
    "                    row = []\n",
    "                    i += 1\n",
    "                    while i < len(lines):\n",
    "                        line_strip = lines[i].strip()\n",
    "                        if not line_strip or not re.match(r'^[-\\d\\s]+$', line_strip) or 'END OF TEC MAP' in line_strip:\n",
    "                            break\n",
    "                        vals = [float(v) if v != '9999' else np.nan for v in line_strip.split()]\n",
    "                        row.extend(vals)\n",
    "                        i += 1\n",
    "                    if len(row) != len(lons):\n",
    "                        print(f\"Warning: Row length {len(row)} != number of longitudes {len(lons)} at epoch {epoch}. Padding/truncating.\")\n",
    "                        row = (row + [np.nan]*len(lons))[:len(lons)]\n",
    "                    grid.append(row)\n",
    "                else:\n",
    "                    i += 1\n",
    "            if len(grid) != len(lats):\n",
    "                print(f\"Warning: Grid row count {len(grid)} != number of latitudes {len(lats)} at epoch {epoch}. Padding/truncating.\")\n",
    "                while len(grid) < len(lats):\n",
    "                    grid.append([np.nan]*len(lons))\n",
    "                grid = grid[:len(lats)]\n",
    "            grid = np.array(grid)\n",
    "            maps.append(grid)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    maps = np.array(maps)  # shape: (n_epochs, n_lat, n_lon)\n",
    "    data = {}\n",
    "    for lat_idx, lat in enumerate(lats):\n",
    "        for lon_idx, lon in enumerate(lons):\n",
    "            data[(lat, lon)] = maps[:, lat_idx, lon_idx]\n",
    "    df = pd.DataFrame(data, index=epochs)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['lat', 'lon'])\n",
    "    return df\n",
    "\n",
    "# Combine all files into a single DataFrame\n",
    "dfs = []\n",
    "for fp in file_paths:\n",
    "    if fp:  # Only try non-empty file paths\n",
    "        try:\n",
    "            print(f\"Processing {fp} ...\")\n",
    "            dfs.append(parse_ionex_file(fp))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {fp}: {e}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise ValueError(\"No valid files found!\")\n",
    "\n",
    "# Concatenate and deduplicate/sort\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df = combined_df[~combined_df.index.duplicated(keep='first')]\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "print(combined_df.head())\n",
    "print(f\"\\nCombined shape: {combined_df.shape}, columns: {len(combined_df.columns)} (lat-lon grid points), times: {len(combined_df.index)}\")\n",
    "\n",
    "# Save for future use\n",
    "combined_df.to_parquet(\"combined_ionex_vtec.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86e1bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ce4101",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
