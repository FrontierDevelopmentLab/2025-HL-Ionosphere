{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb46c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3594d780",
   "metadata": {},
   "source": [
    "Parsing IONEX observational data\n",
    "\n",
    "Loading TIE-GCM model data\n",
    "\n",
    "Interpolating both datasets onto a common grid and timeframe\n",
    "\n",
    "Creating training tensors explicitly saved as X_train.pt and Y_train.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8831e",
   "metadata": {},
   "source": [
    "This is a U-Net––an encoder-decoder network with skip-connections that’s great for tasks where you need both global context and fine spatial detail (e.g., image segmentation or super-resolution). On top of the basic U-Net, it adds AttentionBlocks to each skip path:\n",
    "\n",
    "ConvBlock: two back-to-back Conv → BatchNorm → ReLU layers to extract features at each resolution.\n",
    "\n",
    "AttentionBlock: learns a soft “mask” (via a tiny network + sigmoid) that gates the features coming from the encoder, so the decoder only “pays attention” to the most relevant spatial regions.\n",
    "\n",
    "Putting it together, the AttentionUNet\n",
    "\n",
    "Encodes your input through two downsampling steps (via max-pooling) and ConvBlocks, building up a deep feature map.\n",
    "\n",
    "Decodes by upsampling (ConvTranspose2d), using AttentionBlocks to select which encoder features to pass along, then ConvBlocks to fuse them.\n",
    "\n",
    "Outputs a final 1-channel map (via a 1×1 convolution) matching the input’s spatial dimensions.\n",
    "\n",
    "Why this model?\n",
    "U-Net structure: preserves high-resolution detail through skip-connections\n",
    "\n",
    "Attention: lets the network focus on the most informative features and ignore noise, improving accuracy on tasks where some spatial regions matter more than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e28107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator\n",
    "from skimage.transform import resize\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "file_paths = [\n",
    "    './ionosphere_central/vTEC_data/uqrg1000.24i',\n",
    "    './ionosphere_central/vTEC_data/uqrg1010.24i'\n",
    "]\n",
    "model_directory = './ionosphere_central/CCMC/model_data/TIE-GCM/129/Akshay_Ramesh_042125_IT_5/'\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "SPATIAL_FACTOR = 4\n",
    "\n",
    "# --- Parse IONEX Observations ---\n",
    "def parse_ionex_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    header_end = [i for i, l in enumerate(lines) if 'END OF HEADER' in l][0]\n",
    "    header = lines[:header_end]\n",
    "    for line in header:\n",
    "        if 'LAT1 / LAT2 / DLAT' in line:\n",
    "            lat1, lat2, dlat = map(float, line.split()[:3])\n",
    "        if 'LON1 / LON2 / DLON' in line:\n",
    "            lon1, lon2, dlon = map(float, line.split()[:3])\n",
    "    lats = np.arange(lat1, lat2 - 0.1, -abs(dlat))\n",
    "    lons = np.arange(lon1, lon2 + 0.1, dlon)\n",
    "    maps, epochs = [], []\n",
    "    i = header_end + 1\n",
    "    while i < len(lines):\n",
    "        if 'START OF TEC MAP' in lines[i]:\n",
    "            epoch_line = lines[i+1]\n",
    "            y, mo, d, h, mi, s = map(int, epoch_line[:36].split())\n",
    "            epoch = datetime(y, mo, d, h%24, mi, s) + timedelta(days=h//24)\n",
    "            epochs.append(epoch)\n",
    "            grid = []\n",
    "            i += 2\n",
    "            while 'END OF TEC MAP' not in lines[i]:\n",
    "                if 'LAT/LON1/LON2/DLON/H' in lines[i]:\n",
    "                    row = []\n",
    "                    i += 1\n",
    "                    while lines[i].strip() and 'LAT/LON1/LON2/DLON/H' not in lines[i] and 'END OF TEC MAP' not in lines[i]:\n",
    "                        line_values = re.findall(r'[-+]?[0-9]*\\.?[0-9]+', lines[i])\n",
    "                        vals = [float(v) if v != '9999' else np.nan for v in line_values]\n",
    "                        row.extend(vals)\n",
    "                        i += 1\n",
    "                    if len(row) == len(lons):\n",
    "                        grid.append(row)\n",
    "                else:\n",
    "                    i += 1\n",
    "            if len(grid) == len(lats):\n",
    "                maps.append(grid)\n",
    "        else:\n",
    "            i += 1\n",
    "    maps = np.array(maps)\n",
    "    data = {(lat, lon): maps[:, lat_idx, lon_idx] for lat_idx, lat in enumerate(lats) for lon_idx, lon in enumerate(lons)}\n",
    "    df = pd.DataFrame(data, index=epochs)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['lat', 'lon'])\n",
    "    return df\n",
    "\n",
    "# Combine Observations Safely:\n",
    "dfs = [parse_ionex_file(fp) for fp in file_paths if fp]\n",
    "\n",
    "# Ensure matching columns across all observations\n",
    "common_cols = dfs[0].columns\n",
    "for df in dfs[1:]:\n",
    "    common_cols = common_cols.intersection(df.columns)\n",
    "\n",
    "# Keep only common columns in all dfs\n",
    "dfs_aligned = [df[common_cols] for df in dfs]\n",
    "\n",
    "# Concatenate and remove duplicates\n",
    "obs_df = pd.concat(dfs_aligned)\n",
    "obs_df = obs_df[~obs_df.index.duplicated(keep='first')].sort_index()\n",
    "\n",
    "# Verify dimensions clearly\n",
    "obs_lats = sorted(set(lat for lat, lon in obs_df.columns))\n",
    "obs_lons = sorted(set(lon for lat, lon in obs_df.columns))\n",
    "\n",
    "\n",
    "# --- Load TIE-GCM Model Data ---\n",
    "model_files = sorted([\n",
    "    f for f in os.listdir(model_directory) \n",
    "    if not f.endswith('.json') and f != '.ipynb_checkpoints'\n",
    "])\n",
    "model_grids, model_times = [], []\n",
    "for fname in model_files:\n",
    "    ds = xr.open_dataset(os.path.join(model_directory, fname), engine='netcdf4')\n",
    "    if 'TEC' in ds:\n",
    "        tec, times = ds['TEC'].values / 1e12, pd.to_datetime(ds['time'].values)\n",
    "        model_grids.extend(tec)\n",
    "        model_times.extend(times)\n",
    "model_grids = np.stack(model_grids)\n",
    "model_times = pd.to_datetime(model_times)\n",
    "model_lats, model_lons = ds['lat'].values, ds['lon'].values\n",
    "\n",
    "# --- Interpolation ---\n",
    "common_times = pd.date_range(start=max(obs_df.index.min(), model_times.min()), end=min(obs_df.index.max(), model_times.max()), freq='5min')\n",
    "\n",
    "# Prepare original lat/lon from observational data\n",
    "obs_lats = sorted(set(lat for lat, lon in obs_df.columns))\n",
    "obs_lons = sorted(set(lon for lat, lon in obs_df.columns))\n",
    "\n",
    "obs_grids = []\n",
    "for t in obs_df.index:\n",
    "    obs_values = obs_df.loc[t].values.reshape(len(obs_lats), len(obs_lons))\n",
    "    interp_func = RegularGridInterpolator((obs_lats, obs_lons), obs_values, bounds_error=False, fill_value=np.nan)\n",
    "    \n",
    "    mesh_lats, mesh_lons = np.meshgrid(model_lats, model_lons, indexing='ij')\n",
    "    interp_points = np.column_stack([mesh_lats.ravel(), mesh_lons.ravel()])\n",
    "    \n",
    "    interpolated_grid = interp_func(interp_points).reshape(len(model_lats), len(model_lons))\n",
    "    obs_grids.append(interpolated_grid)\n",
    "\n",
    "obs_grids = np.stack(obs_grids)\n",
    "\n",
    "interp_obs = interp1d(obs_df.index.astype(int), obs_grids, axis=0, bounds_error=False, fill_value='extrapolate')(common_times.astype(int))\n",
    "interp_model = interp1d(model_times.astype(int), model_grids, axis=0, bounds_error=False, fill_value='extrapolate')(common_times.astype(int))\n",
    "\n",
    "# --- Training Data Prep ---\n",
    "data = np.concatenate([interp_obs, interp_model], axis=0)\n",
    "mean, std = np.nanmean(data), np.nanstd(data)\n",
    "np.save('tec_mean.npy', mean)\n",
    "np.save('tec_std.npy', std)\n",
    "\n",
    "data = np.nan_to_num((data - mean) / std)\n",
    "X_train = torch.tensor(data[:, None], dtype=torch.float32)\n",
    "Y_train = torch.tensor(data[:, None], dtype=torch.float32)\n",
    "\n",
    "# Save prepared tensors\n",
    "torch.save(X_train, 'X_train.pt')\n",
    "torch.save(Y_train, 'Y_train.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19cba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "SPATIAL_FACTOR = 4\n",
    "\n",
    "# --- Enhanced Model: Residual Attention UNet ---\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Conv2d(F_int, 1, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        psi = self.relu(self.W_g(g) + self.W_x(x))\n",
    "        psi = self.sigmoid(self.psi(psi))\n",
    "        return x * psi\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=1):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvBlock(in_ch, 64)\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.c2 = ConvBlock(64, 128)\n",
    "        self.p2 = nn.MaxPool2d(2)\n",
    "        self.c3 = ConvBlock(128, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.att2 = AttentionBlock(128, 128, 64)\n",
    "        self.c4 = ConvBlock(256, 128)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.att1 = AttentionBlock(64, 64, 32)\n",
    "        self.c5 = ConvBlock(128, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.c1(x)\n",
    "        c2 = self.c2(self.p1(c1))\n",
    "        c3 = self.c3(self.p2(c2))\n",
    "\n",
    "        u2 = self.up2(c3)\n",
    "        c2 = self.att2(u2, c2)\n",
    "        u2 = torch.cat([u2, c2], dim=1)\n",
    "        c4 = self.c4(u2)\n",
    "\n",
    "        u1 = self.up1(c4)\n",
    "        c1 = self.att1(u1, c1)\n",
    "        u1 = torch.cat([u1, c1], dim=1)\n",
    "        c5 = self.c5(u1)\n",
    "\n",
    "        return self.final(c5)\n",
    "\n",
    "# --- Data Loading (assume preprocessed and normalized tensors) ---\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# --- Initialize Model, Optimizer, Scheduler, Loss ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AttentionUNet().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- Training Loop with Early Stopping ---\n",
    "best_loss = float('inf')\n",
    "patience, trigger = 10, 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for xb, yb in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}'):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    scheduler.step(epoch_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.6f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), 'attention_unet_best.pt')\n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger += 1\n",
    "        if trigger >= patience:\n",
    "            print('Early stopping triggered.')\n",
    "            break\n",
    "\n",
    "# --- Load Best Model ---\n",
    "model.load_state_dict(torch.load('attention_unet_best.pt'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51693041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load previously saved tensors\n",
    "X = torch.load('X_train.pt')\n",
    "Y = torch.load('Y_train.pt')\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure test tensors are on the correct device\n",
    "X_test = X_test.to(device)\n",
    "Y_test = Y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78473b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(X_test).cpu().numpy()\n",
    "\n",
    "Y_test_np = Y_test.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2de18",
   "metadata": {},
   "source": [
    "Plot a frame from the obs vs the model prediction and also plot the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b900ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# --- Load Trained Model ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AttentionUNet().to(device)\n",
    "model.load_state_dict(torch.load('attention_unet_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Assume X_test and Y_test are already loaded and preprocessed\n",
    "# X_test: Low-resolution input grids, Y_test: Ground-truth high-resolution grids\n",
    "\n",
    "# --- Predict ---\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test.to(device)).cpu().numpy()\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "Y_test_np = Y_test.cpu().numpy()\n",
    "\n",
    "# --- De-normalize the predictions and targets ---\n",
    "mean = np.load('tec_mean.npy')\n",
    "std = np.load('tec_std.npy')\n",
    "\n",
    "predictions = predictions * std + mean\n",
    "Y_test_np = Y_test_np * std + mean\n",
    "\n",
    "\n",
    "# --- Select a Sample for Plotting ---\n",
    "idx = 0  # You can change the index to visualize different samples\n",
    "prediction = predictions[idx, 0]\n",
    "observation = Y_test_np[idx, 0]\n",
    "difference = prediction - observation\n",
    "\n",
    "# Define lat/lon grid (assuming known from preprocessing)\n",
    "lats = np.linspace(-90, 90, prediction.shape[0])\n",
    "lons = np.linspace(-180, 180, prediction.shape[1])\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "# --- Plot Static Example ---\n",
    "idx = 0\n",
    "prediction = predictions[idx, 0]\n",
    "observation = Y_test_np[idx, 0]\n",
    "difference = prediction - observation\n",
    "\n",
    "vmin = min(np.nanmin(observation), np.nanmin(prediction))\n",
    "vmax = max(np.nanmax(observation), np.nanmax(prediction))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Observation\n",
    "im0 = axs[0].pcolormesh(lon_grid, lat_grid, observation, shading='auto', cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axs[0].add_feature(cfeature.COASTLINE)\n",
    "axs[0].set_title('Observation (TECU)')\n",
    "plt.colorbar(im0, ax=axs[0], orientation='horizontal', fraction=0.046, pad=0.04, label='TECU')\n",
    "\n",
    "# Prediction\n",
    "im1 = axs[1].pcolormesh(lon_grid, lat_grid, prediction, shading='auto', cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axs[1].add_feature(cfeature.COASTLINE)\n",
    "axs[1].set_title('Model Prediction (TECU)')\n",
    "plt.colorbar(im1, ax=axs[1], orientation='horizontal', fraction=0.046, pad=0.04, label='TECU')\n",
    "\n",
    "# Difference\n",
    "im2 = axs[2].pcolormesh(lon_grid, lat_grid, difference, shading='auto', cmap='RdBu_r', vmin=-np.max(np.abs(difference)), vmax=np.max(np.abs(difference)))\n",
    "axs[2].add_feature(cfeature.COASTLINE)\n",
    "axs[2].set_title('Difference (Prediction - Observation)')\n",
    "plt.colorbar(im2, ax=axs[2], orientation='horizontal', fraction=0.046, pad=0.04, label='Δ TECU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('TECcomparison_example.png')\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474f05a",
   "metadata": {},
   "source": [
    "No time codes taken.. so animation is extra broken!!!! dead end.. start again. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
